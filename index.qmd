---
title: "Oui-Love Plots: Outcome-informed Love plots for covariate balance in causal inference"
format:
  html:
    code-fold: false
jupyter: python3
---


Things to touch on:

* covariate balance
  * a/smd
  * love plot
* structural confounders vs actual confounders
* ASMD alone is not sufficient
* outcome-covariate importance
* augmenting love plot visually
  * visualization channels / markers
* combining ASMD with outcome importance for joint measurement for covariate/model selection
* Methods:
  * balance measures
  * feature importance measures
  * data simulation model
  * love plot (but also other plots like scatter)
  * encoding visual channels

## Abstract

## Introduction
Covariate balancing is a significant and essential concept for causal inference from observational studies.
Generally, balance diagnostics assess the difference in covariate distribution between exposures levels.
Intuitively, if the covariate distribution is the same across exposure groups, there will be no systematic bias in exposure and difference in outcomes will only be due to the exposure status.
Therefore, balancing is the most common diagnostics for assessing balancing methods, like inverse propensity weighting (IPW) or matching [cite that review]. 

Ideally, covariate balance is assessed over \emph{confounding variables}.
These are variables affecting both the exposure and the outcome, 
and which failing to adjust for can introduce bias when examining the influence of the exposure on the outcome.
<!-- Usually, we would like to examine how pre-adjustment confounders differ across exposure groups, and whether adjustment (like IPW or Matching) was able to reduce those differences, effectively eliminating their contribution on the outcome, and therefore isolating the effect of exposure. -->
Adjusting for these confounders reduces their difference across exposure groups,
effectively equaling their influence on the outcome across exposure groups;
thus enabling the model to isolate the effect of the exposure.

Whether a variable is a confounder cannot be determined from the data itself. 
Therefore, the most common approach to select confounders for an adjustment set 
<!-- (and more generally, how any pair of variables interact)  -->
is to let a domain expert hand pick them manually.
The structure arising from this specification is often formulated and presented as a Directed Acyclic Graph (DAG),
where variables are depicted as nodes and two nodes are connected by an arrow if one causally influences the other [cite DAG intro].
<!-- Since This formulation of the structure of the problem, often through a Directed Acylclic Graph (DAG),  -->
When specifying how any pair of variables interact,
the excluction of an edge -- assuming there is no association whatsoever -- is a much stronger assumption than its inclusion -- allowing the model to infer zero association from the data.
Thus, when determining the structure, modellers may prefer to err on the inclusion of edges, rather than their exclusion.

Most importantly, since the structure -- and therefore the confounders -- are determined a-priori, based on prior knowledge rather than data, we denote them \emph{structural confounders}.
However, an a-priori \emph{structural confounder} may not necessarily be an a-posteriori \emph{statistical confounder}.
Namely, the prior assumption a variable is associated with both exposure and outcome may not manifest at the data at hand.
This is quite plausible, even in the absence of finite sampling errors, since we often build DAGs one pair at a time, failing to frasp how many factors may interact to determine the exposure or outcome conditioned on all the other factors.
For instance, a factor we assumed is considered when prescribing medicine may not be used,
or we can fail to understand the mechanism underwhich a certain factor conditionally explains the outcome.
Both will result with the factor not being statistically associated with the exposure or outcome, resepctively (or both).

Covariate balance assessments only capture covariate-exposure associations.
This can be insufficient.
For example, such a putative confounder may heavily influence differential exposure, leading to high imbalance, but have no impact on the outcome (these may be referred to as istruemntal variables).
In such cases, it will be unnecessary (or even harmful [cite z-bias]) to balance over that putative confounder.
However, commonly used diagnostics like the (Absolute) Standardized Mean Difference (ASMD) [cite] and the corresponding Love plot [cite] will fail to capture that and may mislead the researcher to focus on where they should not.

To overcome that, information about the covariate-outcome association should be incorporated to provide a fuller picture.
Fortunately, assessing the statistical importance of a variable on an outcome is a very known problem in regression modeling and machine learning [cite one harrell one ML book].
Assessing covariate-outcome importance will provide us with additional information -- orthogonal to the covariate-exposure balance assessment -- that will allow us to, literally speaking, paint a fuller picture about confounder imbalance.

Our contribution in this manuscript is twofold.
First, we will provide visual augmentation to the known Love plot based on both standardized mean difference and covariate-outcome importance.
Second, we will combine both measures together to suggest better metrics for covariate/model selection.
[TODO: isn't high-dimensional propensity score?].


## Visual
brief introduction to visualization and dimesion and markers and mapping.
explain love plot in terms of visual markers and dimensions
different dimension
map that dimension to additional marker


